Filozofia języka - dział filozofii podejmujący problem natury, pochodzenia oraz użycia języka. Filozofów analitycznych interesują cztery kluczowe problemy: natura znaczenia, użycie języka, rozumienie języka oraz relacja między językiem a rzeczywistością. Dla filozofów kontynentalnych z kolei, filozofia języka rozpatrywana jest nie jako osobne zagadnienie, lecz jako część logiki, historii lub polityki.
Spis treści  [ukryj] 
1 Historia
1.1 Starożytność
1.2 Średniowiecze
1.3 Okres nowożytny
2 Analityczna filozofia języka
2.1 Kompozycja i części
2.2 Natura znaczenia
2.3 Odniesienie
2.3.1 Język i myśl
2.4 Interakcja społeczna i język
3 Język i filozofia kontynentalna
4 Główne problemy filozofii języka
4.1 Niejasność
4.2 Problem uniwersaliów i kompozycji
4.3 Natura języka
4.4 Formalne kontra nieformalne podejścia
4.5 Tłumaczenie i interpretacja
5 Przypisy
6 Bibliografia
7 Linki zewnętrzne
Historia[edytuj]

 Zobacz też: Historia językoznawstwa.
Starożytność[edytuj]
Historia filozofii języka jest ściśle związana z historią językoznawstwa. Najstarsze potwierdzone dociekania lingwistyczne pochodzą z Indii z okresu Wedyjskiego (od ok. 1500 p.n.e.) i związane z deifikacją Wać - „mowy” (trl. vac, jedno z imion Saraswati - wedyjskiej bogini nauki, literatury i sztuk pięknych"[1]). Na Zachodzie refleksja nad mową rozpoczyna się w V wieku p.n.e. wraz z nauczaniem Sokratesa, Platona, Arystotelesa i Stoików[2]. Zarówno w Indiach, jak i w Grecji, spekulacje lingwistyczne poprzedzają pojawienie się tradycji gramatycznych systemowego opisu języka, które powstały około VII wieku p.n.e. w Indiach (gramatyk sanskrytu Jaska) i około III wieku p.n.e. w Grecji ( Rhianus).
W dialogu Kratylos, Platon rozważał czy nazwy przedmiotów są ustalone przez konwencję czy przez naturę. Krytykował konwencjonalizm, ponieważ prowadzi on do konsekwencji, że dzięki umowie wszystko może być określone jakąkolwiek nazwą. W związku z tym, nie można mówić o prawidłowym lub nieprawidłowym zastosowaniu nazwy. Platon twierdził, że istnieje naturalna odpowiedniość nazw. Wskazywał na wyrazy złożone i zdania, które są uznawane za prawidłowe. Twierdził też, że prymitywne nazwy mają naturalną odpowiedniość, ponieważ każdy fonem reprezentuje podstawowe idee lub odczucia. Na przykład, dla Platona litera l i jej dźwięk reprezentowały ideę miękkości. Jakkolwiek, na końcu Kratylosa, Platon zaznaczył, iż niektóre społeczne konwencje są także uwzględnione, zatem w koncepcji mówiącej, że fonemy mają indywidualne znaczenia, są pewne braki.[3]
Arystoteles interesował się zagadnieniami logiki, kategoriami oraz tworzeniem znaczeń. Rozdzielił wszystkie przedmioty na kategorie gatunków i rodzajów. Uważał, że znaczenie predykatu było ustalone poprzez abstrakcję podobieństwa pomiędzy różnymi przedmiotami jednostkowymi. Teoria ta została później nazwana nominalizmem[4]. Ponieważ jednak sam Arystoteles uważał te podobieństwa za konsekwencje wspólnej formy, jest częściej traktowany jako przedstawiciel umiarkowanego realizmu.
Filozofowie stoiccy wnieśli wielki wkład do analizy gramatyki, wyróżniając pięć części mowy: rzeczowniki, czasowniki, apelatywy (nazwy lub epitety), spójniki oraz rodzajniki. Rozwinęli również wyrafinowaną doktrynę lektón, który był związany z każdym znakiem języka, ale oddzielony zarówno od znaku samego w sobie, jak i od rzeczy, do której się odnosi. Ów lektón był znaczeniem (sensem) każdego terminu. Lektónem zdania jest to, co dziś nazywamy sądem w sensie logicznym. Tylko sądy były rozpatrywane w kategorii "nośników prawdy" lub "narzędzi prawdy" (tj., mogły być nazywane prawdziwymi lub fałszywymi), podczas gdy zdania były po prostu ich narzędziami ekspresji. W innym rozumieniu lektá mogły oznaczać również rzeczy poza sądami, np. rozkazy, pytania i wykrzykniki.[5]
Średniowiecze[edytuj]
Właściwa filozofia języka ma swoje korzenie we wczesnośredniowiecznej filozofii indyjskiej (ok. V-X w.). „Materialistyczna” szkoła mimansa prowadzona przez Kumarilę Bhattę oraz Prabhakarę Misrę skłaniała się ku konwencjonalizmowi, uznając rozdzielność językowego przedstawienia od znaczenia. Holistyczna sphota (sansk. ????? , trl. spho?a) - "gramaryjska" szkoła prowadzona przez Bhartryhariego i Mandanamiśrę utrzymywała, że fonetyczne wypowiedzi i znaczenia tworzą niepodzielność – identycznie z Brahmanem (śabda-tattva-brahman). Stanowisko to znalazło kulminację w nauczaniu Waćaspatiego Miśry i późniejszej szkoły nawjanjaja (trl. navyanyaya) .
Europejscy filozofowie średniowiecza byli w dużej mierze zainteresowani subtelnościami języka i jego użycia. Dla wielu scholastyków, to zainteresowanie było spowodowane potrzebą tłumaczenia tekstów greckich na łacinę. W tym okresie można wyróżnić kilku znaczących filozofów języka. Według Petera J. Kinga Piotr Abelard antycypował idee Sensu i nominatu.[6] Summa Logicae Williama Ockhama wprowadziła jedną z pierwszych prób kodyfikacji języka myśli.[7]
Scholastycy czasów późnego średniowiecza, tacy jak Ockham i Jan Duns Szkot, uważali logikę za scientia sermocinalis (naukę języka). Rezultatem ich badań było rozwinięcie pojęć lingwistyczno-filozoficznych, których złożoność i subtelność dopiero niedawno została doceniona. Wiele najbardziej interesujących problemów współczesnej filozofii języka było antycypowanych przez średniowiecznych myślicieli. Zjawiska niejasności i dwuznaczności były głęboko analizowane, co doprowadziło do rosnącego zainteresowania problemami związanymi z użyciem słów synkategorematycznych, jak np. i, lub, jeśli, nie, każdy. Rozwinęło się również badanie słów kategorematycznych (terminów) i ich własności.[8] Szczególnie rozwinięta była scholastyczna doktryna suppositio.[9] Supozycja terminu jest interpretacją daną w szczególnym kontekście. Może być właściwa lub niewłaściwa (gdy jest używana w metaforze, metonimii i innych figurach retorycznych). Z kolei właściwa supozycja może być materialna lub formalna, w zależności od tego, czy odnosi się do swojego zwyczajnego pozajęzykowego odnośnika (np. „Charles jest mężczyzną”) czy do siebie samej jako jednostki lingwistycznej (np. „Charles ma siedem liter”). Taki schemat klasyfikacyjny jest prekursorem współczesnego rozróżnienia między użyciem a znaczeniem oraz pomiędzy językiem i metajęzykiem.[9]
Od XI do XIII rozwijana była również tradycja gramatyki spekulatywnej, której czołowymi przedstawicielami byli Marcin z Dacji i Tomasz z Erfurtu.
Okres nowożytny[edytuj]
Językoznawcy okresu renesansu i baroku, tacy, jak Johannes Goropius Becanus, Athanasius Kircher czy John Wilkins pozostając pod wpływem stopniowego odkrywania chińskich znaków i egipskich hieroglifów byli zafascynowani ideą języka filozoficznego, który przezwyciężyłby wymieszania języków. Myśl ta związana była z ideą, że może istnieć uniwersalny język muzyki.
Europejska nauka zaczęła wchłaniać indyjską tradycję lingwistyczną już od połowy XVIII wieku. Pionierskie były prace Jean François Pons i Henry Thomas Colebrooke nad editio princeps dzieł Waradaradży, XVII-wiecznego gramatyka sanskrytu (wyd. datowane na 1849).
Na początku XIX wieku, duński filozof Soren Kierkegaard nalegał na nasilenie badań nad językiem w filozofii zachodniej. Twierdził on, że filozofia nie jest dostatecznie skoncentrowana na roli, jaką odgrywa język w poznaniu i że przyszła filozofia powinna być rozwijana ze świadomym naciskiem na język:
Jeżeli roszczenia filozofów do bycia bezstronnymi były tym, czym miały być, powinny również brać pod uwagę język wraz z całą jego istotnością w odniesieniu do filozofii spekulatywnej… Język jest częściowo czymś danym pierwotnie, a częściowo tym, co rozwija się swobodnie. Tak, jak indywidualista nigdy nie może osiągnąć punktu, w którym stanie się absolutnie niezależny… tak też jest z językiem.[10]
W związku z tym, pod koniec XIX wieku badanie języka zaczęło odgrywać w filozofii zachodniej kluczową rolę, szczególnie z Port-Royal we Francji, w świecie anglojęzycznym oraz w innych częściach Europy. Fundamentalną pracą był Kurs językoznawstwa ogólnego Ferdinanda de Saussure'a, opublikowany pośmiertnie w 1916.
Filozofia języka stała się tak wszechobecna, że w kręgach filozofii analitycznej rozumiana była jako filozofia w ogóle. W XX wieku ta dominacja problematyki języka rozprzestrzeniła się także na inne tradycje filozoficzne i była określana jako zwrot lingwistyczny.[8]
Analityczna filozofia języka[edytuj]

Zainteresowania analitycznych filozofów języka koncentrują się wokół kilku problemów. Po pierwsze pytają o naturę znaczenia i szukają wyjaśnienia co znaczy „oznaczać” coś. Zagadnienia z tym powiązane dotyczyły natury synonimii, korzeni znaczenia samego w sobie oraz tego, jak jakiekolwiek znaczenie może być rzeczywiście poznane. Innym tematem dociekań z tej grupy jest sposób, za pomocą którego zdania budowane są w znaczącą całość, odrębną od jego poszczególnych części.
Po drugie, chcą oni zrozumieć jak postępują z językiem nadawcy i odbiorcy w komunikacji i jak on jest wykorzystywany w społeczeństwie. Szczególne zainteresowanie budzi nauka języka, tworzenie języka czy akty mowy.
Po trzecie, analitycy chcą wiedzieć jak język odnosi się do umysłów – zarówno mówiącego, jak i interpretatora. Szczególnie interesowała ich płaszczyzna pomyślnego tłumaczenia jednych słów na inne.
Ostatnim wielką grupą zagadnień jest badanie jak język i znaczenie odnoszą się do pojęcia prawdy i do świata. Filozofowie mieli w zwyczaju rzadziej skupiać się na tym, które zdania są faktycznie prawdziwe, niż na pytaniu które rodzaje znaczeń mogą być prawdziwe lub fałszywe. Filozof języka zorientowany na prawdę może zastanawiać się czy bezsensowne zdanie może być prawdziwe lub fałszywe lub czy zdania mogą wyrażać twierdzenia dotyczące rzeczy które nie istnieją, zamiast myśleć o tym, jak zdania są używane.
Kompozycja i części[edytuj]
Od dawna wiadomo, że istnieją różne części mowy, z których składane są przeciętne zdania. Najważniejszym pytaniem zadawanym przez formalistów i strukturalistów jest: „Jak znaczenie całego zdania wynika z jego poszczególnych części?”.
Wiele aspektów problemu kompozycji zdań podejmowanych jest w ramach syntaktyki. Semantyka filozoficzna skupia się na zasadzie kompozycyjności w celu wyjaśnienia relacji między znaczącymi częściami a całymi zdaniami. Zasada kompozycyjności wskazuje, że zdanie może być rozumiane na podstawie znaczenia jego części (np. słów, morfemów) wraz z rozumieniem jego struktury (np. składni, logiki).[11]
W teorii zaproponowanej przez logika Alfreda Tarskiego, leksykalne części zdania wyjaśniane są poprzez odwołanie się do ich warunków spełniania, czyli ogólnie rzecz biorąc, poprzez odwołanie do obiektów, które są zarządzane przez pewne rozumienie: „Aby otrzymać definicję spełniania… musimy wskazać, które obiekty zaspokajają najprostsze funkcje zdaniowe.” Przez „funkcje zdaniowe” Tarski rozumie z grubsza to, co my rozumiemy jako zdanie.[12]
Możliwe jest również użycie pojęcia funkcji do opisania czegoś więcej niż tylko sposobu działania znaczenia leksykalnego: funkcje mogą opisywać również znaczenie zdania. Przykładowo, w zdaniu: „Koń jest czerwony”, możemy rozważać “konia” jako produkt funkcji propozycjonalnej. Funkcja propozycjonalna jest operacją języka, która bierze podmiot (w tym wypadku konia) za dane wejściowe, a jako dane wyjściowe oddaje fakt semantyczny (tzn. sąd „Koń jest czerwony”). Innymi słowy, funkcja propozycjonalna jest jak algorytm. Znaczenie „czerwonego” w tym wypadku jest czymkolwiek, co bierze podmiot „koń” i zmienia go w twierdzenie „Koń jest czerwony”.[13]
Językoznawcy rozwinęli dwie główne metody rozumienia relacji między częściami ciągu językowego i tego, jak są one powiązane: drzewo syntaktyczne i drzewo semantyczne. Drzewo syntaktyczne zajmuje się słowami w zdaniu z gramatyką zdania w tle. Drzewo semantyczne z kolei, skupia się na roli znaczeń słów i jak te znaczenia połączyć, aby zapewnić wgląd w genezę faktów semantycznych.
Natura znaczenia[edytuj]
 Osobny artykuł: Znaczenie.
Odpowiedź na pytanie „czym jest znaczenie?” nie jest nadal oczywista. Zajmuje się nim odrębny dział filozofii języka.
Geoffrey Leech postulował istnienie dwóch zasadniczo różnych typów znaczenia : pojęciowe i skojarzeniowe. Pojęciowe znaczenia ekspresji mają związek z definicjami słów jako takimi i cechami tych definicji. Ten rodzaj znaczenia jest traktowany jako użycie techniki zwanej analizą cech semantycznych. Konceptualne znaczenie wyrażenia nieuchronnie wiąże zarówno definicję (zwaną także "konotacją" lub "intensją") oraz denotację. Skojarzeniowe znaczenie wyrażenia wiąże się z indywidualnym rozumieniem mówiącego. Ono, z kolei, może być rozbite na sześć podtypów: konotacyjne, kolokacyjne, społeczne, afektywne, refleksyjne i tematyczne.[14]
Ogólnie rzecz biorąc, było co najmniej sześć różnych prób wyjaśnienia czym jest językowe "znaczenie". Każda z nich wiąże się z obszerną literaturą przedmiotu:
Ideowa teoria znaczenia, głównie związana z tradycją brytyjskiego empiryzmu Locke’a, Berkeleya i Hume’a, twierdziła, że znaczenia są czysto mentalną treścią wywołaną przez znaki.[15] Chociaż ta koncepcja znaczenia była od początku związana z wieloma problemami, zainteresowanie nią odnowiło się dzięki współczesnym teoretykom semantycznego internalizmu.[16]
Teorie ukierunkowane na prawdę utrzymują, że znaczenie to warunki, pod którymi wyrażenie może być prawdziwe lub fałszywe. Ta tradycja odnosi się do Fregego i wielu współczesnych autorów, na czele z Alfredem Tarskim i Donaldem Davidsonem.[12][17]
Teorie użycia ujmują znaczenie jako związane z aktami mowy i konkretnymi wypowiedziami. Ludwig Wittgenstein wprowadził ideę „znaczenia jako użycia” oraz wspólnotowe spojrzenie na język.[18] Inni przedstawiciele tego stanowiska to P. F. Strawson, John Searle czy Robert Brandom.[19]
Referencyjne teorie znaczenia znane również jako semantyczny eksternalizm, traktują znaczenie jako równoznaczne z tymi rzeczami na świecie, które są istotnie związane ze znakami. Są dwa szerokie podgatunki eksternalizmu: społeczny i środowiskowy. Pierwszy jest bardzo blisko związany z Tylerem Burgem, a drugi z Hilarym Putnamem, Saulem Kripke.[20][21][22]
Weryfikacyjne teorie znaczenia są głównie związane z wczesnym XX-wiecznym ruchem logicznego pozytywizmu. Klasyczne sformułowanie takiej teorii mówi, że znaczenie zdania to metoda jego weryfikacji lub falsyfikacji. W tej formie, została ona odrzucona po publikacji Dwóch Dogmatów Empiryzmu Quine’a i przyjęciu przez większość filozofów tezy Duhema-Quine'a.[23] Mimo to Michael Dummett bronił zmodyfikowanej formy weryfikacjonizmu jeszcze po 1970. W tej wersji, rozumienie (a więc znaczenie) zdania polegało na zdolności słuchacza do rozpoznania przedstawienia (matematycznego, empirycznego lub innego) prawdziwości zdania.[24]
Pragmatyczna teoria znaczenia jest jedyną teorią, w której znaczenie (lub rozumienie) zdania jest zależne od skutków jego zastosowania. Dummett przypisuje tę teorię Charlesowi Sandersowi Peirce’owi i innym XX-wiecznym amerykańskim pragmatystom.[24]
Sformułowano też odrębne teorie, które zajmowały się nie-językowym znaczeniem (tzn. znaczeniem niesionym przez mowę ciała, znaczeniem jako konsekwencją itp.)[25]
Odniesienie[edytuj]
Dociekania na temat tego, jak język odnosi się do świata zwane są teoriami odniesienia. Gottlob Frege podzielił zawartość semantyczną każdego wyrażenia, włącznie ze zdaniami, na dwie części: Sinn (zazwyczaj tłumaczone jako „sens”) and Bedeutung (tłumaczone m.in. jako „znaczenie”, „denotacja”, „nominat” oraz „odniesienie”). Sensem zdania jest myśl, którą ono wyraża. Każda myśl jest abstrakcyjna, uniwersalna i obiektywna. Sens jakiegokolwiek wyrażenia wewnątrz zdania polega na jego wkładzie w myśl, którą wyraża całe zdanie. Sensy determinują odniesienie i są również sposobami prezentacji obiektów, do których odnoszą się wyrażenia. Przedmiot odniesienia może być ten sam, mimo różnych sensów i sposobów jego prezentacji (tak jest np. w przypadku nazw gwiazda wieczorna i gwiazda poranna, odnoszących się do planety Wenus).[26] Teoria Fregego określana jest jako teoria pośredniego odniesienia (referencji).
John Stuart Mill zaproponował inną analizę relacji między znaczeniem i odniesieniem. Według niego, pomimo że są dwa komponenty do rozważenia dla większości pojęć języka (konotacja i denotacja), nazwy własne, jak Bill Clinton, Bismarck lub John Hodgman mają tylko denotację. Stąd stanowisko Milla zostało nazwane teorią bezpośredniego odniesienia.[27]
Bertrand Russell w swoich późniejszych pismach utrzymywał, że tylko bezpośrednio odnoszące się wyrażenia są, jak je nazwał, „nazwami własnymi w sensie logicznym”. Takimi nazwami są wyrażenia takie, jak ja, teraz, tutaj.[28][29] Russell widział nazwy własne jako „skrócone sprecyzowane określenia”. W ten sposób George Washington może być skrótem “pierwszy prezydent Stanów Zjednoczonych”. Sprecyzowane określenia denotują wyrażenia, które są analizowane przez Russella jako egzystencjalnie mierzalne konstrukcje logiczne. Takie wyrażenia denotują w sensie, że istnieje obiekt, który odpowiada opisowi. Jakkolwiek, te obiekty nie mogą być rozważane jako znaczące same w sobie, ale mają znaczenie wyłącznie w sądach wyrażonych przez zdanie, którego są częścią. Dlatego nie są one dla Russella odnośnikami w ten sam sposób jak nazwy własne.[30][31]
Według Fregego, każde odnoszące się wyrażenie ma sens oraz to do czego się odnosi. Takie pośrednie odniesienie ma pewne teoretyczne zalety nad spojrzeniem Milla. Na przykład, nazwy odnoszące się do tego samego obiektu, jak François-Marie Arouet i Voltaire stwarzają problem z bezpośrednim odniesieniem, ponieważ osoba słysząca, że „François-Marie Arouet to Voltaire” może być tym zaskoczona. Tak więc kognitywna treść tych wyrażeń wygląda na różną.[26] Punkt widzenia Milla ma również problem z nazwami pozbawionymi odnośników. Zdanie „Pegaz to skrzydlaty koń z mitologii greckiej” zdaje się być doskonale znaczące, a nawet prawdziwe. Ale, nawiązując do poglądu Milla, “pegaz” nie ma żadnego znaczenia, ponieważ nie ma odniesienia przedmiotowego. Stąd, podążając za zasadą kompozycyjności, zdanie samo w sobie nie jest ani prawdziwe ani fałszywe i nie ma znaczenia. W literaturze odnotowano także kilka innych trudności.[32]
Pomimo różnic między poglądami Fregego i Russella, są oni generalnie ujmowani razem jako deskryptywiści jeżeli chodzi o nazwy własne. Taki deskryptywizm był skrytykowany w Nazywaniu a konieczności Saula Kripke.
Kripke rozwinął tzw. "argument modalny". Rozważmy nazwę Arystoteles i opis "najwybitniejszy uczeń Platona", "twórca logiki" czy "nauczyciel Aleksandra Wielkiego". Arystoteles odpowiada wszystkim tym opisom (i wielu innym, które możemy z nim powiązać), ale nie jest wcale konieczne, aby jeśli istniał Arystoteles, to spełniał w konieczny sposób warunki tych opisów. Arystoteles mógł równie dobrze istnieć bez zrobienia żadnej z tych rzeczy, z których był znany następnym pokoleniom. Mógł istnieć i nie stać się znanym lub umrzeć w dzieciństwie. Załóżmy, że Arystoteles jest powiązany przez Marię z opisem "ostatni wielki filozof antyku", a (faktycznie) Arystoteles umarł jako niemowlę. Wtedy opis Marii będzie odnosił się w rzeczywistości do Platona. Taka jednak perspektywa jest wbrew naszym intuicjom. Dlatego, według Kripke, nazwy są desygnatorami sztywnymi. To znaczy, odnoszą się to tego samego przedmiotu w każdym możliwym świecie, w którym ten przedmiot. W tej samej pracy, Kripke sformułował wiele innych argumentów przeciwko "fregowsko-russellowskiemu" deskryptywizmowi.[22]
Język i myśl[edytuj]
Ważnym problemem który dotyczy zarówno filozofii języka jak i filozofii umysłu jest to w jaki sposób język wpływa na myśl i vice-versa. Istnieje wiele różnych poglądów na tę kwestie które oferują różne spostrzeżenia i propozycje.
Językoznawcy Sapir i Whorf sugerowali że język ogranicza obszar w którym członkowie „językowej wspólnoty” mogą myśleć o pewnych tematach.[33] Innymi słowy język był analitycznie wcześniejszy w stosunku do myśli. Zwolennikiem tej tezy jest również filozof Michael Dummett.[34]
W ostrym przeciwieństwie do stanowiska Sapira-Whorfa leży pogląd że myśl (lub bardziej ogólnie treść myślowa) ma pierwszeństwo przed językiem. Pogląd na pierwszeństwo myśli można znaleźć np. w pracy Paula Grice'a.[34]. Jest on szczególnie kojarzony z Jerrym Fodorem i jego hipotezą języka myśleńskiego. Zgodnie z nią, mówiony i pisany język wywodzi swoją intencjonalność i znaczenie z wewnętrznego języka zakodowanego w umyśle.[35] Głównym argumentem przemawiającym za tym poglądem jest to że struktura myśli i struktura języka zdają się dzielić swój charakter. Kolejnym argumentem jest to że trudno wytłumaczyć jak znaki i symbole na papierze mogą reprezentować cokolwiek znaczącego dopóki nie zostanie im wpojone znaczenie przez zawartość umysłu. Jeden z głównych argumentów przeciwko tej hipotezie głosi, że takie takie rozumowanie sięga do kolejnych poziomów języka, prowadząc do nieskończonego regresu.[35] Hipoteza ta doprowadziła jednak wielu filozofów umysłu i języka (Fodor, Ruth Millikan, Fred Dretske) do skierowania uwagi bezpośrednio na wyjaśnianie znaczenia treści i stanów psychicznych.
Kolejna tradycja filozofów starała się pokazać że język i myśl są ze sobą nierozerwalnie związane, i że nie ma możliwości wytłumaczenia jednego bez drugiego. Donald Davidson w swoim eseju „Myśl i mowa” dowodzi że pojęcie wiary mogło powstać jedynie jako produkt społecznej interakcji językowej. Daniel Dennett utrzymuję zbieżny pogląd na postawy propozycjonalne.[36]
Niektórzy myśliciele jak np. starożytny sofista Gorgiasz, pytali czy język jest w ogóle zdolny do uchwycenia myśli.
...Mowa nie może dokładnie przedstawiać przedmiotów percepcji, ponieważ jest ona różna od nich. Rzeczy postrzegane są ujmowane przez jeden organ a mowa przez inny organ. Tak jak widzialne obiekty nie mogą się przedstawiać innemu zmysłowi niż wzrok i tak jak inne organy zmysłów nie mogą sobie przekazywać danych zmysłowych, tak mowa nie może przekazywać żadnych informacji o rzeczach postrzeganych. Ponieważ przedmioty widziane nie mogą być przedstawione innym narządom, prócz wzroku oraz różne organy zmysłów nie mogą udzielić informacji, siebie wzajemnie, podobnie mowa nie może podać żadnych informacji o postrzeżeniach. Dlatego też, jeśli w coś w ogóle istnieje i jest zrozumiałe, jest niekomunikowalne.[37]
Istnieją badania które dowodzą że języki kształtują to jak ludzie rozumieją przyczynowość. Na przykład Anglicy mają tendencje do mówienia „Jan zbił wazę” nawet jeżeli stało się to przez przypadek. Z kolei Hiszpanie czy Japończycy częściej odpowiadali „Waza się stłukła”. Podczas badań prowadzonych przez Catalin Fausey na Stanford University Anglicy, Hiszpanie i Japończycy oglądali filmy przedstawiające dwoje ludzi dmuchających balony, tłukących jajka i rozlewających napoje zarówno celowo jak i przez przypadek. Później każdy został zapytany czy pamięta kto co zrobił. Hiszpanie i Japończycy nie zapamiętali sprawców przypadkowych wypadków tak dobrze jak zrobili to Anglicy.
Rosjanie którzy w swoim języku mają dodatkowe rozróżnienie pomiędzy jasnym a ciemnym niebieskim mają lepsze zdolności do wizualnego rozróżniania odcieni niebieskiego. Z kolei Piraha, plemię zamieszkujące Brazylię, które posiada tylko określenia mało i wiele zamiast liczb nie jest w stanie śledzić dokładnie ilości.[38]
Istnieją również badania gdzie ludzie byli proszeni o obejrzenie serii obrazków przedstawiających kosmitów. O tym czy dany obcy jest przyjazny czy wrogi decydowały subtelne cechy o których biorący udział w badaniu nie byli poinformowani. Osoby badane musiały zgadnąć który obcy jest przyjazny a który wrogi. Po każdej odpowiedzi informowani byli czy udzielili poprawnej odpowiedzi co miało im pomóc w nauczeniu się subtelnych wskazówek czy obcy jest przyjacielem czy wrogiem. Jedna czwarta uczestników została wcześniej poinformowana że przyjacielscy obcy to „leebish” a wrodzy to „grecious” natomiast kolejna ćwiartka uczestników została poinformowana odwrotnie. Dla reszty uczestników obcy pozostali bezimienni. Okazało się że osoby które znały imiona nauczyły się znacznie szybciej rozróżniać obcych osiągając 80% poprawność w mniej niż połowie czasu którego potrzebowali nie znający imion. Pod koniec testu osoby znające imiona potrafiły właściwie pokategoryzować 88% obcych natomiast druga grupa osiągnęła 80% poprawności. Badacze doszli do wniosku że nazywanie obiektów pomaga nam w ich rozróżnianiu i zapamiętywaniu.
W innym eksperymencie grupa ludzi została poproszona o obejrzenie mebli z katalogu IKEA. Przez połowę czasu proszeni byli o nazywanie przedmiotów na przykład lampa czy krzesło. Pozostały czas służył do określenia czy podobało się to czy nie. Okazało się że podczas gdy osoby miały nazywać przedmioty trudniej było im przypomnieć sobie szczegóły tych przedmiotów np. czy krzesło miało oparcia czy nie. Wnioskowano że nazywanie obiektów pomaga naszemu umysłowi budować prototyp typowego przedmiotu w grupie bez cech indywidualnych.[39]
Interakcja społeczna i język[edytuj]
Według szerokiej opinii język jest określany jest przez społeczne konwencje. Rodzi ona jednak szereg pytań, np.: „Czym dokładnie jest konwencja i jak ją badać?", lub; „W jakim zakresie konwencje mają znaczenie dla nauki o języku?”. Według Davida Kelloga Lewisa konwencja jest racjonalnie samo-odtwarzającą się regularnością w zachowaniu.[34]
Niektórzy badacze podważali istotność konwencji dla nauki o znaczeniu. Noam Chomsky zaproponował aby nauka o języku była uprawiana w terminach języka wewnętrznego. Gdyby było to możliwe, omijałoby to problem wyjaśniania poprzez konwencję i przesuwałaby je w domenę „metasemantyki”. Metasemantyka to termin użyty przez filozofa języka Roberta Station'a w celu określenia wszystkich tych dziedzin które usiłują wyjaśnić jak powstają semantyczne podstawy twierdzeń.[13] Jedną z obiecujących dziedzin badań dotyczy społecznych warunków, które mają wpływ lub są powiązane ze znaczeniem i językiem. Etymologia (nauka o pochodzeniu słów) i Stylistyka (filozoficzna argumentacja dotycząca tego co czyni dobrą gramatykę względem konkretnego języka) to dwa kolejne przykłady dyscyplin metasemantycznych.
Konwencja językowa badana była przez wiele oddzielnych (choć powiązanych) dyscyplin. Filozofów języka interesują podstawy teoretyczne tych dyscyplin i to jak widzą one problematykę języka. Na przykład jednym z głównych paradygmatów socjologii, interakcjonizm symboliczny, oparty jest na spostrzeżeniu że u podstaw ludzkiej organizacji społecznej leży pojęcie znaczenia.[40] W konsekwencji jakiekolwiek wyjaśnienia struktury społecznej (np. instytucji) powinny uwzględnić wspólne znaczenia które tworzą i utrzymują strukturę.
Retoryka Retoryka zajmuje się badaniem pewnych słów których ludzie używają w celu osiągnięcia właściwego efektu emocjonalnego i racjonalnego u słuchacza np. aby przekonać, sprowokować, zdobyć względy czy uczyć. Kilka istotnych zastosowań retoryki obejmuje badanie propagandy i dydaktyzmu, analizy celów przeklinania i wyrażeń pejoratywnych (zwłaszcza jak wpływają one na zachowania innych, a także jak określają relacje), lub językowe struktury płci kulturowe. Może być także wykorzystywana do badania przejrzystości językowej (mówienia w przystępny sposób), jak również wypowiedzi performatywnych i różnych zdań za pomocą których "działa się językiem" (tzw. akty mowy). Ma także zastosowanie do analiz i wykładni prawa a także pomaga dać wgląd do logicznej koncepcji uniwersum dyskursu.
Teoria literatury jest dyscypliną, która ściśle się wiążę z filozofią języka. Zajmuje się metodami za pomocą których czytelnicy i krytycy rozumieją pewne teksty. Dyscyplina ta jest spadkobiercą tradycji badania jak prawidłowo interpretować przekazy i jest silnie związana z hermeneutyką.
Język i filozofia kontynentalna[edytuj]

W filozofii kontynentalnej, język nie jest pojmowany jako osobna dyscyplina tak jak ma to miejsce w filozofii analitycznej. Jest on raczej nierozerwalnie powiązany z wieloma innymi obszarami myśli takim jak Fenomenologia, Semiotyka, Hermeneutyka, ontologia Heideggera, egzystencjalizm, strukturalizm, dekonstrukcjonizm i teoria krytyczna. Idea języka jest często odnoszona do logiki w rozumieniu greckiego logosu znaczącego dyskurs lub dialektykę. Język i pojęcia są również postrzegane jako uformowane przez tradycje i politykę lub nawet filozofie historyczną.
W XX w. począwszy od Martina Heidegger'a na polu języka i ontologii filozofii kontynentalnej znaczącą role odegrała hermeneutyka i teoria interpretacji. Heidegger łączy fenomenologie z hermeneutyką Wilhelma Dilthey'a. Wierzył on że język jest jedną z najważniejszych kategorii Dasein: "Language is the house of being, which is propriated by being and pervaded by being."[41] Jednakże Heidegger uważał że dzisiejszy język jest zniszczony z powodu nadużywania ważnych słów i nieodpowiedni dla nauki w głębi Bycia (Sein). Na przykład „Sein” samo w sobie zawiera wiele znaczeń. Stąd też Heidegger wymyślił nowe słownictwo i style językowe, oparte na greka i germańskich etymologicznych relacjach słowa by wyeliminować dwuznaczność zwykle używanych słów. Unika słów takich jak świadomość, ego, człowiek, natura itd. zamiast tego mówi o holistycznym Byciu-w-świecie, Dasein.
Z pomocą nowej idei Bycia-w-świecie Heidegger konstruuje swoją teorię języka skoncentrowaną wokół mowy. Wierzył że mowa (mówienie, słuchanie, milczenie) była najbardziej podstawową i czystą formą języka. Heidegger twierdzi że pisanie jest jedynie uzupełnieniem mowy ponieważ nawet czytelnik konstruuje lub ma wpływ na swoją własną „rozmowę” podczas czytania. Najważniejszą cechą języka jest jego projektywność oraz idea tego że język jest wcześniejszy niż ludzka mowa. Oznacza to że gdy ktoś zostaje „wrzucony” w świat jego byt jest charakteryzowany od samego początku przez pewne przedrozumienia świata. Jednakże dzieje się to po nazywaniu lub "articulation of intelligibility", can one have primary access to Dasein and Being-in-the-World.[42]
Hans-Georg Gadamer rozszerzył pomysły Heideggera i zaproponował kompletną ontologię hermeneutyczną. W „Prawdzie i metodzie” Gadamer opisuje język jako „medium w którym zachodzi konkretne zrozumienie i zgoda między dwojgiem ludzi.."[43]W dodatku Gadamer twierdzi że świat jest lingwistycznie ukonstytuowany i nie może istnieć bez języka. Na przykład pomniki i posągi nie mogą komunikować się bez pomocy języka. Gadamer twierdzi również że każdy język konstytuuję postrzeganie świata ponieważ językowa natura świata uwalnia każdą osobę od obiektywnego środowiska: „...fakt że posiadamy świat jest w pełni uzależniony od języka i objawia się w nim. Świat jako świat istnieje dla człowieka jak dla żadnego innego stworzenia na ziemi.” "[43]
Paul Ricour, zaproponował odmienną hermeneutykę mającą swój rodowód w oryginalnym greckim sensie tego słowa z naciskiem na odkrywanie ukrytych znaczeń dwuznacznych wyrazów (lub symboli) języka potocznego. Innymi filozofami popierającymi tą tradycje są Luigi Pareyson i Jacques Derrida.[44]
Semiotyka jest nauką zajmującą się znakami i symbolami w obrębie ich transmisji recepcji i znaczenia. Na tym polu język ludzki (naturalny i sztuczny) jest tylko jedną wśród wielu dróg którymi ludzie (i inne świadome byty) mogą się ze sobą komunikować. To pozwala im wykorzystać i skutecznie manipulować światem zewnętrznym w celu stworzenia znaczenie dla siebie i przekazać to znaczenie innym. Każdy przedmiot każda osoba każde wydarzenie i każdy czynnik nieprzerwanie coś komunikuje (lub znaczy). Dzwonek telefonu na przykład oznacza telefon. Dym który unosi się nad horyzontem oznacza ogień. Dym oznacza. W tym wyobrażeniu wszystkie przedmioty świata wydają się być precyzyjnie określone dla inteligentnych istot które muszą tylko dokonać ich interpretacji. Wszystko ma znaczenie. Prawdziwa komunikacja zawiera użycie języka jednakże wymaga tego by ktoś (nadawca) nadał wiadomość lub tekst w pewnym kodzie do kogoś innego (odbiorca). Język jest badany jedynie o ile jest jedną z powyższych form (najbardziej wyszukaną formą) komunikacji. Najważniejszymi osobami w historii semiotyki są Charles Sanders Peirce, Roland Barthes, i Roman Jakobson. Do współczesnych i najbardziej znanych badaczy semiotyki zaliczyć można Umberto Eco, A.J. Greimas, Louis Hjelmslev, i Tullio De Mauro.[44] Badaniem znaków w aspekcie komunikacji pozaludzkiej zajmuje się Biosemiotyka która powstała w końcu lat 90tych XX w. Założycielami są Thomas Sebeok i Thure Von Uexkuell
Główne problemy filozofii języka[edytuj]

Niejasność[edytuj]
Jednym z problemów niepokojących filozofów języka i logików jest problem niejasność słów. Szczególnym przypadkiem niejasności są tak zwane przypadki graniczne w których nie można określić czy zdanie jest prawdziwe czy fałszywe. Klasycznym przykładem są „wysoki” lub „łysy”. W granicznym przypadku nie można orzec czy ktoś jest wysoki czy nie-wysoki. W konsekwencji niejasność prowadzi do tak zwanego Paradoksu stosu. Wielu teoretyków próbowało rozwiązać paradoks przy pomocy logiki wielowartościowej takiej jak logika rozmyta, które radykalnie zrywają z klasyczną dwuwartościową logiką.[45]
Problem uniwersaliów i kompozycji[edytuj]
 Osobny artykuł: Spór o uniwersalia.
Sprawą która interesuje wielu filozofów jest spór o uniwersalia. Dla przykładu ktoś może zapytać „Kiedy ludzie wypowiadają słowo skała co jest tym co to słowo reprezentuje?”. Pojawiły się dwie różne odpowiedzi na to pytanie. Jedni twierdzili że wyrażenie reprezentuje realne abstrakcyjne uniwersalia, inni twierdzili że słowo reprezentuje pewien zbiór konkretnych indywidualnych klas, którym przypisujemy przynależność do wspólnej kategorii. Pierwsze z powyższych stanowisk nazywane było realizmem filozoficznym, drugie nominalizmem.[46]
Problem uniwersaliów może być wytłumaczony jeżeli przeanalizujemy zdanie „Sokrates jest człowiekiem”
Z perspektywy radykalnego realizmu powiązanie pomiędzy S i M jest powiązaniem pomiędzy dwoma abstrakcyjnymi podmiotami. Jest podmiot człowiek i podmiot Sokrates. Te dwa podmioty łączą się ze sobą w pewien sposób bądź pokrywają się ze sobą.

Z perspektywy nominalistycznej powiązanie między S i M jest powiązaniem między konkretnym podmiotem Socrates i obszernym zbiorem konkretnych podmiotów (ludzi) Mówiąc że Sokrates jest człowiekiem to to samo co mówić że Sokrates jest częścią kategorii Ludzie.
Jest jeszcze trzecie stanowisko, między nominalizmem a realizmem radykalnym, zwykle nazywane "umiarkowanym realizmem". Przypisywane jest ono Arystotelesowi i Tomaszowi z Akwinu. Umiarkowani realiści utrzymują ,że słowo "człowiek" odnosi się do rzeczywistej istoty lub tworu, który jest rzeczywiście obecny i identyczny z Socratesem i wszystkimi innymi ludźmi , ale "człowiek" nie istnieje jako podmiot odrębny i różny. . To jest realizm sytuacji, ponieważ "człowiek" jest prawdziwy, o ile rzeczywiście istnieje we wszystkich ludziach, ale jest to realizm umiarkowany, bo "człowiek" nie jest podmiotem niezależnym od mężczyzn lecz informuje.
Natura języka[edytuj]
Wiele filozoficznych dyskusji zaczyna się od wyjaśnienia terminologii. Jedynym z elementów który poddawany jest analizie znaczenie jest języka sam w sobie. Filozofowie którzy postawili przed sobą zadanie analizy znaczenia języka zadają dwa ważne pytania: „Czym jest język w ogóle?” i „Co jest poszczególnym jednostkowym językiem?”
Niektóre semiotyczne poglądy podkreślały że język jest wyłącznie manipulacją i użyciem symboli w celu skupienia uwagi na oznaczonej treści. Gdyby tak było w istocie, ludzie nie byliby jedynymi posiadaczami językowych umiejętności.[44] Z drugiej jednak strony wiele prac językoznawcy Noama Chomsky'ego kładło nacisk na rolę składni jako cechy charakterystycznej każdego języka.[47]
Bardziej intrygujące zdaje się być pytanie co odróżnia poszczególne języki od siebie. Co sprawia że język „angielski” jest językiem angielskim.? Jaka jest różnica między językiem hiszpańskim i francuskim? Chomsky wskazał że poszukiwania istoty języka należy rozpocząć od badania wewnętrznego języka osób lub I-języków, które są oparte na jasnych regułach (lub zasadach i parametrach) które tworzą gramatyki. Pogląd ten jest częściowo poparty przekonaniem, że nie istnieje żadna jasna ogólna i nadrzędna różnica pomiędzy językami. Inne próby, które określa mianem E-języków, miały wyjaśnić język jako użycie w określonej wspólnocie językowej z określonym zbiorem uformowanych w umyśle wypowiedzi. (markedly associated with linguists like Bloomfield).[48]
Formalne kontra nieformalne podejścia[edytuj]
Kolejnym z pytań, które dzieli filozofów języka, jest to w jakim zakresie logika formalna może być stosowana jako skuteczne narzędzie do analizy i zrozumienia języka naturalnego. Większość filozofów, w tym Frege, Alfred Tarski i Rudolf Carnap, było mniej lub bardziej sceptycznie nastawionych do formalizacji języków naturalnych, wielu z nich rozwinęło języki formalne mające zastosowanie w naukach lub do badań sformalizowanych częściach języka naturalnego. Najbardziej prominentni członkowie tradycji formalnej semantyka to Tarski, Carnap, Richard Montague and Donald Davidson.[49]
Po drugiej stronie linii podziału, szczególnie widocznego w 1950 i 60., byli tak zwani "filozofowie języka potocznego". Filozofowie tacy jak P. F. Strawson, John Langshaw Austin i Gilbert Ryle podkreślali znaczenie nauki języka naturalnego bez względu na warunki prawdziwości zdań i odniesienia do warunków. Nie wierzyli, że społeczny i praktyczny wymiar znaczenia językowego mógłby zostać uchwycony przez jakiekolwiek próby formalizacji przy pomocy narzędzi logiki. Logika to jedno, a język jest czymś zupełnie innym. Ważne nie są wyrażenia same w sobie, ale to, do czego ludzie ich używają w komunikacie.[50]
Stąd, Austin opracował teorię aktów mowy , które opisują rzeczy, które można zrobić mówiąc (twierdzenie, komendy, zapytania, wykrzyknik) w różnych kontekstach i przy różnych okazjach.[51] Strawson twierdził, że truth table semantics logiczne spójniki (e.g., , and ) Nie oddają znaczenia ich naturalnych odpowiedników języka ("i", "lub" oraz "jeśli to").[52] Podczas gdy ruch "zwykłego języka" w zasadzie zanikł w 1970, jego wpływ był istotny dla rozwoju obszarów teorii aktów mowy i badań pragmatyki. Wiele z jego pomysłów zostało wchłoniętych przez teoretyków, takich jak Kent Bach, Robert Brandom, Paul Horwich and Stephen Neale.[19]
Mając na uwadze powyższe tradycje pytanie, czy istnieje lub nie podstawa do konfliktu pomiędzy podejściami formalnymi i nieformalnymi jest dalekie od rozstrzygnięcia. Niektórzy teoretycy, jak Paul Grice,byli sceptycznie nastawieni do twierdzeń, że istnieje poważny konflikt między logiką i językiem naturalnym.[53]
Tłumaczenie i interpretacja[edytuj]
Tłumaczenie i interpretacja to dwa inne problemy, którym filozofowie języka próbowali stawić czoło. W 1950 roku, W.V. Quine powiedział się za nieokreślonością znaczenia i odniesienia opartego na zasadzie radykalnego tłumaczenia. W Word and Object, Quine zwraca się do czytelnika aby ten wyobraził sobie sytuację, w której ma do czynienia z wcześniej niepoznanym, prymitywnym plemieniem i musi spróbować zrozumieć sens wypowiedzi i gestykulacji, które jego członkowie wykonują. Jest to sytuacja radykalnego tłumaczenia.[54]
Twierdził, że w takiej sytuacji nie jest możliwe w zasadzie być absolutnie pewnym znaczenia lub odniesienia, jakie język mówcy z prymitywnego plemienia przywiązuje do wypowiedzi. Na przykład, jeśli mówca widzi królik i mówi: "gavagai", to czy wypowiedź ta odnosi się do całego królika, ogonu królika czy skroniowej części królika? Wszystko co można zrobić to zbadać wypowiedzi jako części ogólnego zachowania językowego jednostki, a następnie użyć tych uwag do interpretacji znaczenia wszystkich innych wypowiedzi. Na tej podstawie można sformułować instrukcję tłumaczenia. Jednakże odniesienie nie jest z góry określone więc będzie wiele takich instrukcji, gdzie o żadnej nie będzie można orzec że jest lepsza od pozostałych. Dla Quine'a, tak jak dla Wittgenstein, i Austin, znaczenie nie jest czymś powiązanym z pojedynczym słowem czy zdaniem ale jest raczej czymś co jeżeli można przypisać w ogóle to może być przypisane do całego języka.[54] Jest to tak zwany holizm semantyczny.
Zainspirowany dyskusją Quine'a Donald Davidson rozwinął idee radykalnego tłumaczenia do interpretacji wyrażeń i zachowań w ramach jednej wspólnoty językowej. Nazwał ten pogląd radykalną interpretacją. Zasugerował, że znaczenie które każda osoba przypisuje do zdania może być określone tylko przez przypisywanie znaczeń wielu o ile nie wszystkim indywidualnym twierdzeniom jak również ich stanom psychicznym i postawom.[17]
